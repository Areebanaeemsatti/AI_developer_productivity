{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import gradio as gr\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Load dataset\n",
        "data = pd.read_csv(\"/content/ai_dev_productivity.csv\")\n",
        "\n",
        "# Validate required columns\n",
        "required_cols = [\n",
        "    'hours_coding', 'coffee_intake_mg', 'distractions', 'sleep_hours',\n",
        "    'commits', 'bugs_reported', 'ai_usage_hours', 'cognitive_load', 'task_success'\n",
        "]\n",
        "missing_cols = [col for col in required_cols if col not in data.columns]\n",
        "if missing_cols:\n",
        "    raise ValueError(f\"Missing columns in CSV: {missing_cols}\")\n",
        "\n",
        "# Coffee level categorization function\n",
        "def coffee_category(mg):\n",
        "    if mg < 450:\n",
        "        return 'Low'\n",
        "    elif mg <= 600:\n",
        "        return 'Medium'\n",
        "    else:\n",
        "        return 'High'\n",
        "\n",
        "# Feature Engineering\n",
        "data['coffee_level'] = data['coffee_intake_mg'].apply(coffee_category)\n",
        "\n",
        "# Label encode coffee level with fixed classes\n",
        "le = LabelEncoder()\n",
        "le.fit(['Low', 'Medium', 'High'])\n",
        "data['coffee_level_encoded'] = le.transform(data['coffee_level'])\n",
        "\n",
        "# Interaction feature\n",
        "data['coding_ai_interaction'] = data['hours_coding'] * data['ai_usage_hours']\n",
        "\n",
        "# Final feature set\n",
        "features = [\n",
        "    'hours_coding', 'coffee_intake_mg', 'distractions', 'sleep_hours',\n",
        "    'commits', 'bugs_reported', 'ai_usage_hours', 'cognitive_load',\n",
        "    'coding_ai_interaction', 'coffee_level_encoded'\n",
        "]\n",
        "target = 'task_success'\n",
        "\n",
        "# X and y\n",
        "X = data[features]\n",
        "y = data[target]\n",
        "\n",
        "# Scaling\n",
        "scaler = StandardScaler()\n",
        "X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=features)\n",
        "\n",
        "# Train/Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Model Training\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# ----------------- Gradio Interface ---------------- #\n",
        "\n",
        "# Prediction function\n",
        "def predict_task_success(hours_coding, coffee_intake_mg, distractions, sleep_hours,\n",
        "                         commits, bugs_reported, ai_usage_hours, cognitive_load):\n",
        "    input_df = pd.DataFrame([[hours_coding, coffee_intake_mg, distractions, sleep_hours,\n",
        "                              commits, bugs_reported, ai_usage_hours, cognitive_load]],\n",
        "                            columns=['hours_coding', 'coffee_intake_mg', 'distractions', 'sleep_hours',\n",
        "                                     'commits', 'bugs_reported', 'ai_usage_hours', 'cognitive_load'])\n",
        "\n",
        "    # Add interaction\n",
        "    input_df['coding_ai_interaction'] = input_df['hours_coding'] * input_df['ai_usage_hours']\n",
        "\n",
        "    # Add coffee level\n",
        "    coffee_level = coffee_category(coffee_intake_mg)\n",
        "    if coffee_level not in le.classes_:\n",
        "        return f\"âŒ Error: Unrecognized coffee level '{coffee_level}'\"\n",
        "    input_df['coffee_level_encoded'] = le.transform([coffee_level])[0]\n",
        "\n",
        "    # Final preprocessing\n",
        "    final_input = input_df[features]\n",
        "    final_input_scaled = pd.DataFrame(scaler.transform(final_input), columns=features)\n",
        "\n",
        "    # Predict\n",
        "    pred = model.predict(final_input_scaled)[0]\n",
        "    return \"âœ… Productive Day Achieved!\" if pred == 1 else \"âŒ Productivity Goal Missed\"\n",
        "\n",
        "# Static accuracy text\n",
        "def show_model_accuracy():\n",
        "    return \"ðŸ” Model Accuracy:\\n\\nâœ… Random Forest Accuracy: 88% (approximate)\\nðŸ“ˆ Tuned on scaled inputs with interaction + coffee level\"\n",
        "\n",
        "# Plot selection function\n",
        "def show_insight_plot(plot_name):\n",
        "    return plot_name  # assumes plot files exist in same folder\n",
        "\n",
        "# ----------- Gradio Tabs ----------- #\n",
        "\n",
        "# Tab 1: Accuracy\n",
        "accuracy_tab = gr.Interface(\n",
        "    fn=show_model_accuracy,\n",
        "    inputs=[],\n",
        "    outputs=\"text\",\n",
        "    title=\"ðŸ”¢ Model Accuracy\"\n",
        ")\n",
        "\n",
        "# Tab 2: Insight Visuals\n",
        "insights_tab = gr.Interface(\n",
        "    fn=show_insight_plot,\n",
        "    inputs=gr.Radio([\n",
        "        \"coffee_vs_commits.png\",\n",
        "        \"coffee_vs_success.png\",\n",
        "        \"ai_vs_cognitive.png\",\n",
        "        \"ai_vs_success.png\",\n",
        "        \"coding_hours_vs_success.png\"\n",
        "    ], label=\"Choose Insight Plot\"),\n",
        "    outputs=gr.Image(type=\"filepath\"),\n",
        "    title=\"ðŸ“Š Productivity Insights\"\n",
        ")\n",
        "\n",
        "# Tab 3: Prediction\n",
        "predict_tab = gr.Interface(\n",
        "    fn=predict_task_success,\n",
        "    inputs=[\n",
        "        gr.Number(label=\"Hours Coding\"),\n",
        "        gr.Number(label=\"Coffee Intake (mg)\"),\n",
        "        gr.Number(label=\"Distractions\"),\n",
        "        gr.Number(label=\"Sleep Hours\"),\n",
        "        gr.Number(label=\"Commits\"),\n",
        "        gr.Number(label=\"Bugs Reported\"),\n",
        "        gr.Number(label=\"AI Usage (Hours)\"),\n",
        "        gr.Number(label=\"Cognitive Load (1-10)\")\n",
        "    ],\n",
        "    outputs=\"text\",\n",
        "    title=\"ðŸ¤– Task Success Predictor\"\n",
        ")\n",
        "\n",
        "# Launch Gradio with tabs\n",
        "gr.TabbedInterface(\n",
        "    [accuracy_tab, insights_tab, predict_tab],\n",
        "    tab_names=[\"Model Accuracy\", \"Insights\", \"Productivity Predictor\"]\n",
        ").launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "LhqQ0l7AFJDQ",
        "outputId": "180b76d9-0aa8-4dcd-d385-df31cbe39609"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "Number.__init__() got an unexpected keyword argument 'placeholder'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-61-2425196219.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0mfn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpredict_task_success\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m     inputs=[\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNumber\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ðŸ§‘â€ðŸ’» Hours Coding\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplaceholder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"e.g. 6.5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m         \u001b[0mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNumber\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"â˜• Coffee Intake (mg)\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplaceholder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"e.g. 500\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNumber\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ðŸ“± Distractions\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplaceholder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"e.g. 3\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/gradio/component_meta.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Number.__init__() got an unexpected keyword argument 'placeholder'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import gradio as gr\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Load dataset\n",
        "data = pd.read_csv(\"/content/ai_dev_productivity.csv\")\n",
        "\n",
        "# Feature engineering\n",
        "def coffee_category(mg):\n",
        "    if mg < 450:\n",
        "        return 'Low'\n",
        "    elif mg <= 600:\n",
        "        return 'Medium'\n",
        "    else:\n",
        "        return 'High'\n",
        "\n",
        "data['coffee_level'] = data['coffee_intake_mg'].apply(coffee_category)\n",
        "\n",
        "le = LabelEncoder()\n",
        "le.fit(['Low', 'Medium', 'High'])\n",
        "data['coffee_level_encoded'] = le.transform(data['coffee_level'])\n",
        "data['coding_ai_interaction'] = data['hours_coding'] * data['ai_usage_hours']\n",
        "\n",
        "features = [\n",
        "    'hours_coding', 'coffee_intake_mg', 'distractions', 'sleep_hours',\n",
        "    'commits', 'bugs_reported', 'ai_usage_hours', 'cognitive_load',\n",
        "    'coding_ai_interaction', 'coffee_level_encoded'\n",
        "]\n",
        "target = 'task_success'\n",
        "\n",
        "X = data[features]\n",
        "y = data[target]\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=features)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_scaled, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Prediction function\n",
        "def predict_task_success(hours_coding, coffee_intake_mg, distractions, sleep_hours,\n",
        "                         commits, bugs_reported, ai_usage_hours, cognitive_load):\n",
        "    input_df = pd.DataFrame([[hours_coding, coffee_intake_mg, distractions, sleep_hours,\n",
        "                              commits, bugs_reported, ai_usage_hours, cognitive_load]],\n",
        "                            columns=['hours_coding', 'coffee_intake_mg', 'distractions', 'sleep_hours',\n",
        "                                     'commits', 'bugs_reported', 'ai_usage_hours', 'cognitive_load'])\n",
        "\n",
        "    input_df['coding_ai_interaction'] = input_df['hours_coding'] * input_df['ai_usage_hours']\n",
        "    coffee_level = coffee_category(coffee_intake_mg)\n",
        "    input_df['coffee_level_encoded'] = le.transform([coffee_level])[0]\n",
        "\n",
        "    final_input = input_df[features]\n",
        "    final_input_scaled = pd.DataFrame(scaler.transform(final_input), columns=features)\n",
        "\n",
        "    pred = model.predict(final_input_scaled)[0]\n",
        "    return (\n",
        "        \"ðŸŽ¯ Great Job! You are likely to succeed in your tasks today. ðŸš€\"\n",
        "        if pred == 1 else\n",
        "        \"âš ï¸ Oops! Productivity may be impacted today. Try adjusting sleep or distractions.\"\n",
        "    )\n",
        "\n",
        "# Accuracy function\n",
        "def show_model_accuracy():\n",
        "    return (\n",
        "        \"ðŸ“Š **Model Evaluation Report**\\n\\n\"\n",
        "        \"- âœ… **Algorithm:** Random Forest Classifier\\n\"\n",
        "        \"- âš™ï¸ **Accuracy:** ~88%\\n\"\n",
        "        \"- ðŸ” Features: Scaled inputs + coffee interaction + cognitive load\\n\"\n",
        "        \"- ðŸ§  Useful for: Developer productivity prediction!\"\n",
        "    )\n",
        "\n",
        "# Plot selector\n",
        "def show_insight_plot(plot_name):\n",
        "    return plot_name\n",
        "\n",
        "# Tab 1: Accuracy\n",
        "accuracy_tab = gr.Interface(\n",
        "    fn=show_model_accuracy,\n",
        "    inputs=[],\n",
        "    outputs=gr.Markdown(),\n",
        "    title=\"ðŸ“ˆ Model Performance Dashboard\",\n",
        "    theme='default',\n",
        "    css=\"body { text-align: center; }\"\n",
        ")\n",
        "\n",
        "# Tab 2: Visual Insights\n",
        "insights_tab = gr.Interface(\n",
        "    fn=show_insight_plot,\n",
        "    inputs=gr.Radio(\n",
        "        [\"coffee_vs_commits.png\", \"coffee_vs_success.png\", \"ai_vs_cognitive.png\", \"ai_vs_success.png\", \"coding_hours_vs_success.png\"],\n",
        "        label=\"ðŸ“Œ Choose a Visual Insight\",\n",
        "        info=\"Explore how variables like AI usage, coffee, and coding hours affect success\"\n",
        "    ),\n",
        "    outputs=gr.Image(type=\"filepath\", label=\"ðŸ“Š Visualization\"),\n",
        "    title=\"ðŸ” Developer Productivity Insights\"\n",
        ")\n",
        "\n",
        "# Tab 3: Prediction\n",
        "predict_tab = gr.Interface(\n",
        "    fn=predict_task_success,\n",
        "    inputs=[\n",
        "        gr.Number(label=\"ðŸ§‘â€ðŸ’» Hours Coding\"),\n",
        "        gr.Number(label=\"â˜• Coffee Intake (mg)\"),\n",
        "        gr.Number(label=\"ðŸ“± Distractions\"),\n",
        "        gr.Number(label=\"ðŸ›Œ Sleep Hours\"),\n",
        "        gr.Number(label=\"âœ… Commits\"),\n",
        "        gr.Number(label=\"ðŸž Bugs Reported\"),\n",
        "        gr.Number(label=\"ðŸ¤– AI Usage (Hours)\"),\n",
        "        gr.Number(label=\"ðŸ§  Cognitive Load (1-10)\")\n",
        "    ],\n",
        "    outputs=gr.Textbox(label=\"ðŸŽ¯ Prediction Result\", lines=3),\n",
        "    title=\"ðŸ§ª Task Success Predictor\",\n",
        "    allow_flagging=\"never\"\n",
        ")\n",
        "\n",
        "# Combine all in Tabbed Interface\n",
        "gr.TabbedInterface(\n",
        "    [accuracy_tab, insights_tab, predict_tab],\n",
        "    tab_names=[\"ðŸ“Š Accuracy\", \"ðŸ“· Visual Insights\", \"ðŸŽ¯ Predict Productivity\"]\n",
        ").launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 681
        },
        "id": "b2SyOoFGGO-M",
        "outputId": "e6bc807f-f5f4-4d41-ab9f-924b9afa0455"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/gradio/interface.py:416: UserWarning: The `allow_flagging` parameter in `Interface` is deprecated.Use `flagging_mode` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://db6c1ae9fd31196a9c.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://db6c1ae9fd31196a9c.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    }
  ]
}